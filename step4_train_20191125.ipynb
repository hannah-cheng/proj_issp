{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T14:46:23.940215Z",
     "start_time": "2019-11-25T14:46:23.925723Z"
    }
   },
   "outputs": [],
   "source": [
    "log_root = r'D:\\issp_data\\features_total'\n",
    "out_folder = r'C:\\Users\\howard810804\\Desktop\\proj_issp'\n",
    "fraction = 3\n",
    "\n",
    "model_folder = r'D:\\issp_data'\n",
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T14:20:06.706640Z",
     "start_time": "2019-11-25T14:19:56.776857Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import Tuple\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "\n",
    "from distributed.protocol.serialize import register_generic\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tpot import TPOTClassifier\n",
    "register_generic(TPOTClassifier)\n",
    "\n",
    "from xgboost import XGBClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T14:20:12.526841Z",
     "start_time": "2019-11-25T14:20:12.506762Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(st: int, ed: int) -> Tuple['np.array']:\n",
    "    path = os.path.join(log_root, sorted(os.listdir(log_root))[0])\n",
    "    col_nums = dd.read_csv(path, compression='zip')\\\n",
    "                    .compute()\\\n",
    "                    .shape[-1]\n",
    "    \n",
    "    arr_X, arr_y = np.zeros(col_nums).reshape((-1, col_nums)), np.array([0])\n",
    "    \n",
    "    for fl in os.listdir(log_root)[(st - 1) * 3: ed * 3]:\n",
    "        cata = int(fl[31])\n",
    "        path = os.path.join(log_root, fl)\n",
    "        tmp = dd.read_csv(path, compression='zip')\\\n",
    "                .compute()\\\n",
    "                .values\n",
    "        \n",
    "        arr_X = np.vstack((arr_X, tmp))\n",
    "        arr_y = np.hstack((arr_y, np.array([cata] * tmp.shape[0])))\n",
    "        \n",
    "    return arr_X[1:, ], arr_y[1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T14:49:22.075010Z",
     "start_time": "2019-11-25T14:46:29.135651Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(1981656, 55) (1981656,)\n",
      "(660552, 55) (660552,)\n"
     ]
    }
   ],
   "source": [
    "arr_X, arr_y = load_data(1, 12)\n",
    "X, y = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "                replace=False, stratify=arr_y, random_state=None)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=None)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T11:32:55.047422Z",
     "start_time": "2019-11-25T11:32:54.884542Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Wall time: 100 ms\n",
      "0.6641452344931922 \n",
      "\n",
      "[[274  33  12]\n",
      " [ 81  95  24]\n",
      " [ 33  39  70]] \n",
      "\n",
      "[0.02273802 0.02265463 0.02525208 0.01902999 0.03569033 0.03456387\n",
      " 0.03628048 0.02736197 0.03487184 0.03888614 0.11772831 0.02757442\n",
      " 0.04761128 0.03970159 0.05259087 0.08738589 0.01692057 0.02138192\n",
      " 0.01173042 0.01321383 0.00872564 0.01149711 0.00389506 0.01197418\n",
      " 0.00965308 0.00281713 0.00916236 0.01562314 0.0150336  0.00589713\n",
      " 0.01067132 0.01286883 0.01224468 0.01140621 0.00536117 0.01005927\n",
      " 0.00767197 0.00353355 0.00262316 0.00831709 0.00595099 0.01048866\n",
      " 0.00842386 0.00339008 0.00212576 0.00365615 0.00336342 0.0013262\n",
      " 0.00227038 0.00534511 0.00327859 0.00371878 0.00451405 0.00402084\n",
      " 0.02592304]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=1)]: Using backend SequentialBackend with 1 concurrent workers.\n",
      "[Parallel(n_jobs=1)]: Done   1 out of   1 | elapsed:    0.0s remaining:    0.0s\n",
      "[Parallel(n_jobs=1)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    }
   ],
   "source": [
    "# # Random forest\n",
    "\n",
    "# clf_rf = RandomForestClassifier(verbose=2)\n",
    "# %time clf_rf.fit(X_train, y_train)\n",
    "# y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "# print(clf_rf.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(clf_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T11:33:00.464672Z",
     "start_time": "2019-11-25T11:33:00.063338Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 316 ms\n",
      "0.6459909228441755 \n",
      "\n",
      "[[298  17   4]\n",
      " [121  69  10]\n",
      " [ 41  41  60]] \n",
      "\n",
      "[0.01555373 0.01420506 0.01599135 0.01658675 0.04164705 0.02867285\n",
      " 0.02320657 0.01174269 0.03579159 0.05142997 0.06744742 0.02641756\n",
      " 0.03113275 0.01796577 0.06417587 0.09580206 0.02562008 0.01199064\n",
      " 0.01211566 0.01573296 0.01543887 0.01672826 0.01011847 0.01375541\n",
      " 0.01420945 0.00705409 0.01257342 0.01220268 0.01470464 0.01353141\n",
      " 0.01436605 0.01180101 0.0138908  0.01313389 0.01046144 0.01659115\n",
      " 0.01257973 0.013035   0.00709733 0.01016099 0.01011469 0.00955905\n",
      " 0.00852899 0.00945708 0.00796377 0.00557914 0.00456893 0.00718341\n",
      " 0.00479742 0.00544287 0.00886144 0.01308546 0.00807849 0.00714822\n",
      " 0.01296857]\n"
     ]
    }
   ],
   "source": [
    "# # ExtraTrees Classifier\n",
    "\n",
    "# clf_ext = ExtraTreesClassifier(bootstrap=False, criterion='gini', \n",
    "#                                max_features=0.1, min_samples_leaf=3, \n",
    "#                                min_samples_split=2, n_estimators=100)\n",
    "\n",
    "# %time clf_ext.fit(X_train, y_train)\n",
    "# y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "# print(clf_ext.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(clf_ext.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T16:41:31.669562Z",
     "start_time": "2019-11-25T16:00:18.511687Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 40min 53s\n",
      "0.7053903402003173 \n",
      "\n",
      "[[282671  43578   8582]\n",
      " [ 64434 110018  18934]\n",
      " [ 25219  33858  73258]] \n",
      "\n",
      "[0.00330407 0.00476033 0.         0.00342138 0.02871323 0.\n",
      " 0.01202916 0.01172903 0.05577864 0.08491588 0.23254359 0.03602332\n",
      " 0.00859231 0.         0.25359854 0.0148772  0.08219305 0.00182651\n",
      " 0.         0.02720093 0.         0.03114225 0.00904447 0.00725591\n",
      " 0.02686838 0.01211861 0.00685867 0.00242126 0.002258   0.00152336\n",
      " 0.00235119 0.         0.00707296 0.00701709 0.         0.\n",
      " 0.         0.         0.00189595 0.00866268 0.         0.00118199\n",
      " 0.         0.         0.00189934 0.         0.         0.00595812\n",
      " 0.00165404 0.         0.         0.         0.         0.\n",
      " 0.00130855]\n"
     ]
    }
   ],
   "source": [
    "# XGBClassifier\n",
    "\n",
    "# clf_xgb = XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
    "#                         colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
    "#                         learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
    "#                         min_child_weight=1, missing=None, n_estimators=100, \n",
    "#                         n_jobs=1, nthread=None, objective='multi:softprob', \n",
    "#                         random_state=0, reg_alpha=0, reg_lambda=1, \n",
    "#                         scale_pos_weight=1, seed=None, silent=None, \n",
    "#                         subsample=1, verbosity=1)\n",
    "\n",
    "clf_xgb = XGBClassifier()\n",
    "\n",
    "%time clf_xgb.fit(X_train, y_train)\n",
    "y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "print(clf_xgb.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "print(clf_xgb.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T17:08:33.268827Z",
     "start_time": "2019-11-25T17:08:32.898541Z"
    }
   },
   "outputs": [],
   "source": [
    "md_pa = os.path.join(model_folder, r'model_no-settings.p')\n",
    "with gzip.GzipFile(md_pa, 'wb') as file:\n",
    "    pickle.dump(clf_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T17:21:45.418011Z",
     "start_time": "2019-11-25T17:21:43.069976Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0.25359854102134705, 'dr_kurtosis'),\n",
       " (0.23254358768463135, 'dr_median'),\n",
       " (0.0849158763885498, 'dr_mean'),\n",
       " (0.0821930468082428, 'OS'),\n",
       " (0.05577864497900009, 'dr_max'),\n",
       " (0.03602331876754761, 'dr_min'),\n",
       " (0.03114224597811699, '世代'),\n",
       " (0.028713231906294823, 'ts_std'),\n",
       " (0.027200929820537567, '年齢(5才刻み)'),\n",
       " (0.026868382468819618, 'メディアターゲット区分'),\n",
       " (0.014877201057970524, 'dr_skew'),\n",
       " (0.012118610553443432, '未既婚'),\n",
       " (0.01202915795147419, 'ts_kurtosis'),\n",
       " (0.011729031801223755, 'ts_skew'),\n",
       " (0.0090444665402174, '性別'),\n",
       " (0.008662676438689232, '同居配偶者年齢(5才刻み)'),\n",
       " (0.00859230849891901, 'dr_std'),\n",
       " (0.007255910895764828, '性年代'),\n",
       " (0.007072962820529938, '最終学歴'),\n",
       " (0.007017085328698158, '家族人数'),\n",
       " (0.006858667358756065, '職業'),\n",
       " (0.005958118010312319, '家族人員(6〜11才(小学生))'),\n",
       " (0.004760328680276871, 'ts_mean'),\n",
       " (0.003421379718929529, 'ts_min'),\n",
       " (0.003304066602140665, 'ts_max'),\n",
       " (0.002421256620436907, '職業(詳細)'),\n",
       " (0.0023511946201324463, '個人年収'),\n",
       " (0.0022580036893486977, '職種'),\n",
       " (0.001899339840747416, '家族人員(17才以下女子)'),\n",
       " (0.0018959548324346542, '配偶者の同居有無'),\n",
       " (0.0018265119288116693, '居住都道府県(参考)'),\n",
       " (0.0016540366923436522, '家族人員(12〜14才(中学生))'),\n",
       " (0.0015233566518872976, '仕事環境'),\n",
       " (0.0013085498940199614, 'ウエイトセル'),\n",
       " (0.0011819851351901889, '同居配偶者職業'),\n",
       " (0.0, '自動車(自家用車保有)有無'),\n",
       " (0.0, '生協加入有無'),\n",
       " (0.0, '末子年齢'),\n",
       " (0.0, '年齢(10才刻み)'),\n",
       " (0.0, '居住エリア'),\n",
       " (0.0, '家族構成'),\n",
       " (0.0, '家族人員(65才以上)'),\n",
       " (0.0, '家族人員(3〜5才(就学前児童))'),\n",
       " (0.0, '家族人員(17才以下男子)'),\n",
       " (0.0, '家族人員(15〜17才(高校生))'),\n",
       " (0.0, '家族人員(0〜2才(乳児))'),\n",
       " (0.0, '家屋形態'),\n",
       " (0.0, '同居配偶者年齢(10才刻み)'),\n",
       " (0.0, '同居子供人数（17才以下）'),\n",
       " (0.0, '同居子供人数（14才以下）'),\n",
       " (0.0, '世帯年収'),\n",
       " (0.0, 'ts_var'),\n",
       " (0.0, 'ts_median'),\n",
       " (0.0, 'dr_var'),\n",
       " (0.0, '1ヶ月平均小遣い')]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = r'D:\\issp_data\\features_total\\s35809_MobileApp_201701_104628_0_features.csv'\n",
    "df = dd.read_csv(path, sep='\\t', compression='zip')\n",
    "cols = list(df.compute())\n",
    "cols = cols[0].split(',')\n",
    "\n",
    "features = clf_xgb.feature_importances_\\\n",
    "                .tolist()\n",
    "\n",
    "result = [(fea, col) for (fea, col) in zip(features, cols)]\n",
    "result.sort(reverse=True)\n",
    "result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T11:34:31.321817Z",
     "start_time": "2019-11-25T11:33:21.092503Z"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=20, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.6926021107674648\n",
      "Generation 2 - Current best internal CV score: 0.6926021107674648\n",
      "Generation 3 - Current best internal CV score: 0.6926021107674648\n",
      "\n",
      "Best pipeline: XGBClassifier(CombineDFs(input_matrix, input_matrix))\n",
      "Wall time: 1min 10s\n",
      "0.6747352496217852\n",
      "TPOTClassifier(config_dict={'xgboost.XGBClassifier': {}}, crossover_rate=0.1,\n",
      "               cv=5, disable_update_check=False, early_stop=None, generations=3,\n",
      "               max_eval_time_mins=5, max_time_mins=None, memory=None,\n",
      "               mutation_rate=0.9, n_jobs=-1, offspring_size=None,\n",
      "               periodic_checkpoint_folder=None, population_size=5,\n",
      "               random_state=None, scoring=None, subsample=1.0, template=None,\n",
      "               use_dask=True, verbosity=2, warm_start=False)\n"
     ]
    }
   ],
   "source": [
    "# config_dict = {\n",
    "#     'xgboost.XGBClassifier': {\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# clf = TPOTClassifier(generations=3, \n",
    "#                      population_size=5, \n",
    "#                      n_jobs=-1,\n",
    "#                      verbosity=2,\n",
    "#                      config_dict=config_dict,\n",
    "#                      random_state=None,\n",
    "#                      use_dask=True)\n",
    "\n",
    "# %time clf.fit(X_train, y_train)\n",
    "# print(clf.score(X_test, y_test))\n",
    "# print(clf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T11:36:47.366204Z",
     "start_time": "2019-11-25T11:36:47.319317Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('xgbclassifier', XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
      "              colsample_bynode=1, colsample_bytree=1, gamma=0,\n",
      "              learning_rate=0.1, max_delta_step=0, max_depth=3,\n",
      "              min_child_weight=1, missing=None, n_estimators=100, n_jobs=1,\n",
      "              nthread=None, objective='multi:softprob', random_state=0,\n",
      "              reg_alpha=0, reg_lambda=1, scale_pos_weight=1, seed=None,\n",
      "              silent=None, subsample=1, verbosity=1)) \n",
      "\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'fit'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<timed eval>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'fit'"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'tuple' object has no attribute 'score'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-16-d9b305b166b7>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[1;31m# y_pred = best_type.predict(X_test)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'\\n'\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m \u001b[1;31m# print(confusion_matrix(y_test, y_pred), '\\n')\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbest_type\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfeature_importances_\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'tuple' object has no attribute 'score'"
     ]
    }
   ],
   "source": [
    "# best_type = clf.fitted_pipeline_.steps[1]\n",
    "# print(best_type, '\\n')\n",
    "\n",
    "# %time best_type.fit(X_train, y_train)\n",
    "# # y_pred = best_type.predict(X_test)\n",
    "\n",
    "# print(best_type.score(X_test, y_test), '\\n')\n",
    "# # print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(best_type.feature_importances_)\n",
    "\n",
    "# md_pa = os.path.join(model_folder, r'model_clf2.dat')\n",
    "# with open(md_pa, 'wb') as file:\n",
    "#     pickle.dump(best_type, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
