{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T11:56:58.091906Z",
     "start_time": "2019-11-28T11:56:58.060632Z"
    }
   },
   "outputs": [],
   "source": [
    "log_root = r'D:\\issp_data\\features_total'\n",
    "out_folder = r'C:\\Users\\howard810804\\Desktop\\proj_issp'\n",
    "fraction = 1\n",
    "\n",
    "model_folder = r'D:\\issp_data\\model'\n",
    "test_size = 0.25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T11:57:01.794031Z",
     "start_time": "2019-11-28T11:57:01.725053Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from distributed.protocol.serialize import register_generic\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tpot import TPOTClassifier\n",
    "register_generic(TPOTClassifier)\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T11:57:06.594096Z",
     "start_time": "2019-11-28T11:57:06.547223Z"
    }
   },
   "outputs": [],
   "source": [
    "def load_data(st: int, ed: int) -> Tuple['np.array']:\n",
    "    path = os.path.join(log_root, sorted(os.listdir(log_root))[0])\n",
    "    col_nums = dd.read_csv(path, compression='zip').shape[-1]\n",
    "    arr_X, arr_y = np.zeros(col_nums).reshape((-1, col_nums)), np.array([0])\n",
    "    \n",
    "    for fl in os.listdir(log_root)[(st - 1) * 3: ed * 3]:\n",
    "        cata = int(fl[31])\n",
    "        path = os.path.join(log_root, fl)\n",
    "        print(path)\n",
    "        tmp = dd.read_csv(path, compression='zip')\\\n",
    "                .compute()\\\n",
    "                .values\n",
    "        \n",
    "        arr_X = np.vstack((arr_X, tmp))\n",
    "        arr_y = np.hstack((arr_y, np.array([cata] * tmp.shape[0])))\n",
    "        \n",
    "    return arr_X[1: , :], arr_y[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T18:40:36.266285Z",
     "start_time": "2019-11-27T18:40:36.228540Z"
    }
   },
   "outputs": [],
   "source": [
    "# def load_data_month(fl_ls: List[str], fraction: int) -> Tuple['np.array']:\n",
    "#     _ = os.path.join(log_root, sorted(os.listdir(log_root))[0])\n",
    "#     arr_X, arr_y = np.array([])\\\n",
    "#             .reshape((-1, dd.read_csv(_, compression='zip')\\\n",
    "#             .shape[-1])), np.array([])\n",
    "    \n",
    "#     for fl in fl_ls:\n",
    "#         cata, path = int(fl[31]), os.path.join(log_root, fl)\n",
    "#         tmp = dd.read_csv(path, compression='zip')\\\n",
    "#                 .compute()\\\n",
    "#                 .values\n",
    "        \n",
    "#         arr_X = np.vstack((arr_X, tmp))\n",
    "#         arr_y = np.hstack((arr_y, np.array([cata] * tmp.shape[0])))\n",
    "        \n",
    "#     X, y = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "#                     replace=False, stratify=arr_y, random_state=None)\n",
    "    \n",
    "#     X_train, X_test, y_train, y_test = train_test_split(\n",
    "#         X, y, test_size=test_size, random_state=None)\n",
    "    \n",
    "#     return X_train, X_test, y_train, y_test\n",
    "\n",
    "# # fl_ls = os.listdir(log_root)\n",
    "# # print(fl_ls)\n",
    "# # load_data_month(fl_ls[:3], 30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T11:57:10.345103Z",
     "start_time": "2019-11-28T11:57:10.313859Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importances(model_obj) -> List:\n",
    "    path = lambda x: os.path.join(x, os.listdir(x)[0])\n",
    "    df = dd.read_csv(path(log_root), sep='\\t', compression='zip')\n",
    "    cols = list(df.compute())[0].split(',')\n",
    "\n",
    "    features = model_obj.feature_importances_\\\n",
    "                    .tolist()\n",
    "    result = [(fea, col) for (fea, col) in zip(features, cols)]\n",
    "    return sorted(result, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T12:00:15.487239Z",
     "start_time": "2019-11-28T11:57:15.731011Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\issp_data\\features_total\\s35809_MobileApp_201701_104628_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201701_104628_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201701_104628_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201702_104645_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201702_104645_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201702_104645_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201703_104646_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201703_104646_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201703_104646_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201704_104647_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201704_104647_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201704_104647_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201705_104648_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201705_104648_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201705_104648_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201706_104649_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201706_104649_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201706_104649_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201707_104650_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201707_104650_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201707_104650_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201708_104651_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201708_104651_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201708_104651_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201709_104652_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201709_104652_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201709_104652_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201710_104653_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201710_104653_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201710_104653_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201711_104654_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201711_104654_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201711_104654_2_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201712_104655_0_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201712_104655_1_features.csv\n",
      "D:\\issp_data\\features_total\\s35809_MobileApp_201712_104655_2_features.csv\n"
     ]
    }
   ],
   "source": [
    "arr_X, arr_y = load_data(1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T12:00:21.716663Z",
     "start_time": "2019-11-28T12:00:15.516967Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(19816, 65) (19816,)\n",
      "(6606, 65) (6606,)\n"
     ]
    }
   ],
   "source": [
    "X, y = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "                replace=False, stratify=arr_y, random_state=None)\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(\n",
    "    X, y, test_size=test_size, random_state=None)\n",
    "\n",
    "print(X_train.shape, y_train.shape)\n",
    "print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-28T12:03:17.568Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ba01d25337804a2ba8f6d9f54d415da0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, description='Optimization Progress', max=40, style=ProgressStyle(descripti…"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generation 1 - Current best internal CV score: 0.7210337142279506\n",
      "\n",
      "\n",
      "TPOT closed during evaluation in one generation.\n",
      "WARNING: TPOT may not provide a good pipeline if TPOT is stopped/interrupted in a early generation.\n",
      "\n",
      "\n",
      "TPOT closed prematurely. Will use the current best pipeline.\n",
      "\r"
     ]
    }
   ],
   "source": [
    "config_dict = {\n",
    "    'xgboost.XGBClassifier': {\n",
    "    },\n",
    "    'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "    },\n",
    "    'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "    }\n",
    "}\n",
    "\n",
    "clf = TPOTClassifier(generations=3,\n",
    "                     population_size=10, \n",
    "                     n_jobs=-1,\n",
    "                     verbosity=2,\n",
    "                     config_dict=config_dict,\n",
    "                     random_state=None,\n",
    "                     use_dask=True)\n",
    "\n",
    "%time clf.fit(X_train, y_train)\n",
    "print(clf.fitted_pipeline_.steps[1])\n",
    "\n",
    "print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T09:59:07.432865Z",
     "start_time": "2019-11-28T09:50:44.958271Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10building tree 2 of 10building tree 3 of 10\n",
      "\n",
      "building tree 4 of 10\n",
      "\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:  7.7min finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 7min 57s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    9.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fraction: 1\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    8.4s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.7777984675443165 \n",
      "\n",
      "[[884004  97360  25730]\n",
      " [135350 395451  46059]\n",
      " [ 60000  75828 261874]] \n",
      "\n",
      "[0.02671566 0.01449006 0.00764694 0.00943158 0.01579771 0.01577381\n",
      " 0.01572045 0.01582526 0.01825655 0.0208648  0.0173462  0.01741488\n",
      " 0.02381033 0.05464337 0.02765648 0.02443092 0.05147059 0.10803755\n",
      " 0.01943834 0.02124994 0.02140405 0.02553    0.03984851 0.02674785\n",
      " 0.05684549 0.0293212  0.03324171 0.01733779 0.00979577 0.01111745\n",
      " 0.00605091 0.00806537 0.00230594 0.00720775 0.00698933 0.00187512\n",
      " 0.00652165 0.01025316 0.0100657  0.00681628 0.01028307 0.01240999\n",
      " 0.01066363 0.00876685 0.00589019 0.00976296 0.0078401  0.00377352\n",
      " 0.00175238 0.0064583  0.00445656 0.00781766 0.00519817 0.00214119\n",
      " 0.00216748 0.00128221 0.00137513 0.00175563 0.00152245 0.0016021\n",
      " 0.00275752 0.00351031 0.00389189 0.00349346 0.01606478]\n"
     ]
    }
   ],
   "source": [
    "# # Random forest\n",
    "\n",
    "# clf_rf = RandomForestClassifier(verbose=2, n_jobs=-1)\n",
    "# %time clf_rf.fit(X_train, y_train)\n",
    "# y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction)\n",
    "# print(clf_rf.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(clf_rf.feature_importances_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T11:46:29.755123Z",
     "start_time": "2019-11-28T11:25:58.588095Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 18min 52s\n",
      "fraction: 3\n",
      "0.8260621419661132 \n",
      "\n",
      "[[302315  27266   5885]\n",
      " [ 34091 146950  11451]\n",
      " [ 16326  19876  96392]] \n",
      "\n",
      "[0.01598173 0.00602292 0.00747779 0.00660891 0.00722444 0.00720368\n",
      " 0.00723895 0.00723508 0.0209168  0.01326456 0.00693649 0.00601206\n",
      " 0.0512395  0.03711365 0.05391975 0.02857365 0.04935964 0.05883397\n",
      " 0.01486982 0.03025712 0.02119741 0.03835331 0.05296085 0.03073117\n",
      " 0.04007977 0.02979854 0.03526601 0.01390352 0.01273685 0.01305409\n",
      " 0.00879134 0.01136555 0.00417863 0.0085135  0.00888788 0.00280659\n",
      " 0.00971187 0.01125185 0.01214509 0.01081509 0.0117858  0.01337232\n",
      " 0.01367622 0.01130805 0.00864022 0.01399578 0.01274583 0.01048712\n",
      " 0.00298907 0.00725779 0.00634211 0.00769236 0.00527811 0.00480141\n",
      " 0.00474715 0.0024305  0.00288093 0.0033019  0.00287838 0.00309321\n",
      " 0.00598014 0.00856064 0.00521275 0.00468997 0.0130128 ]\n"
     ]
    }
   ],
   "source": [
    "# ExtraTrees Classifier\n",
    "\n",
    "clf_ext = ExtraTreesClassifier(bootstrap=False, criterion='gini', \n",
    "                               max_features=0.1, min_samples_leaf=3, \n",
    "                               min_samples_split=2, n_estimators=100,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "%time clf_ext.fit(X_train, y_train)\n",
    "y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction)\n",
    "print(clf_ext.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "print(feature_importances(clf.ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-28T09:37:03.430375Z",
     "start_time": "2019-11-28T09:36:56.842746Z"
    }
   },
   "outputs": [],
   "source": [
    "# ExtraTrees Classifier\n",
    "\n",
    "clf_ext = ExtraTreesClassifier(bootstrap=False, class_weight=None, \n",
    "                               criterion='gini', max_depth=None, \n",
    "                               max_features='auto', max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, min_samples_leaf=1, \n",
    "                               min_samples_split=2, \n",
    "                               min_weight_fraction_leaf=0.0, n_estimators=10, \n",
    "#                                n_jobs=None, \n",
    "                               n_jobs=-1, \n",
    "                               oob_score=False, \n",
    "                               random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "%time clf_ext.fit(X_train, y_train)\n",
    "y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction, 'score:', clf_ext.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "print(feature_importances(clf_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T15:02:38.522179Z",
     "start_time": "2019-11-27T14:51:38.872231Z"
    }
   },
   "outputs": [],
   "source": [
    "# # ExtraTrees Classifier\n",
    "\n",
    "# clf_ext = ExtraTreesClassifier(bootstrap=False, class_weight=None, \n",
    "#                                criterion='gini', max_depth=None, \n",
    "#                                max_features='auto', max_leaf_nodes=None,\n",
    "#                                min_impurity_decrease=0.0, \n",
    "#                                min_impurity_split=None, min_samples_leaf=1, \n",
    "#                                min_samples_split=2, \n",
    "#                                min_weight_fraction_leaf=0.0, n_estimators=10, \n",
    "#                                n_jobs=None, oob_score=False, \n",
    "#                                random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "# %time clf_ext.fit(X_train, y_train)\n",
    "# y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_ext.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(feature_importances(clf_ext))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T18:30:56.678611Z",
     "start_time": "2019-11-27T18:30:28.273165Z"
    }
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "# param = {\n",
    "#     'tree_method': 'gpu_hist', \n",
    "#     'gpu_id': 0\n",
    "# }\n",
    "# clf_xgb = xgb.XGBClassifier(**param)\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(feature_importances(clf_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T18:28:56.139146Z",
     "start_time": "2019-11-27T18:28:29.785259Z"
    }
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "# # param = {\n",
    "# #     'tree_method': 'gpu_hist', \n",
    "# #     'gpu_id': 0\n",
    "# # }\n",
    "# clf_xgb = xgb.XGBClassifier()\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(feature_importances(clf_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T18:26:40.003544Z",
     "start_time": "2019-11-27T18:26:14.463610Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "\n",
    "# # clf_xgb = XGBClassifier()\n",
    "# clf_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', \n",
    "#                             colsample_bylevel=1, colsample_bynode=1, \n",
    "#                             colsample_bytree=1, gamma=0, learning_rate=0.1, \n",
    "#                             max_delta_step=0, max_depth=3, min_child_weight=1,\n",
    "#                             missing=None, n_estimators=100, n_jobs=1, \n",
    "# #                             nthread=None, \n",
    "#                             nthread=None, objective='multi:softprob', \n",
    "#                             random_state=0, reg_alpha=0, reg_lambda=1, \n",
    "#                             scale_pos_weight=1, seed=None, silent=None, \n",
    "#                             subsample=1, verbosity=1)\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(feature_importances(clf_xgb))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T19:11:08.585923Z",
     "start_time": "2019-11-27T19:11:08.570340Z"
    }
   },
   "outputs": [],
   "source": [
    "# def load_DMatrix(Xt: 'np.array', yt: 'np.array', \n",
    "#                  frac: int) -> Tuple['np.array']:\n",
    "#     step, i = Xt.size // frac, 0\n",
    "    \n",
    "#     while i <= frac:\n",
    "#         st, ed = i * step, (i + 1) * step\n",
    "        \n",
    "# #         yield Xt[st: ed], yt[st: ed]\n",
    "#         yield xgb.DMatrix(Xt[st: ed], label=yt[st: ed])\n",
    "        \n",
    "#         i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T19:09:17.185746Z",
     "start_time": "2019-11-27T19:09:17.154504Z"
    }
   },
   "outputs": [],
   "source": [
    "# for (x, y) in load_DMatrix(arr_X, arr_y, fraction):\n",
    "#     print(x.size)\n",
    "#     print(y.size)\n",
    "# #     rret\n",
    "# # 0\n",
    "# # 1717435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2019-11-27T19:19:19.026Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Specify sufficient boosting iterations to reach a minimum\n",
    "# num_round = 3\n",
    "\n",
    "# # Leave most parameters as default\n",
    "# param = {\n",
    "# #     'subsample': 1 / fraction,\n",
    "#     'objective': 'multi:softmax',  # Specify multiclass classification\n",
    "#     'num_class': 3,  # Number of possible output classes\n",
    "#     'tree_method': 'gpu_hist'  # Use GPU accelerated algorithm\n",
    "# }\n",
    "\n",
    "# # Convert input data from numpy to XGBoost format\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train, nthread=-1)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test, nthread=-1)\n",
    "# # evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "# evallist = [(dtest, 'test')]\n",
    "# gpu_res = {}  # Store accuracy result\n",
    "\n",
    "# # Train model\n",
    "# tmp = time.time()\n",
    "# bst = xgb.train(param, \n",
    "#                 dtrain, \n",
    "# #                 load_DMatrix(arr_X, arr_y, fraction),\n",
    "#                 num_boost_round=num_round, \n",
    "#                 evals=evallist, evals_result=gpu_res)\n",
    "# print(f'GPU Training Time: {time.time() - tmp} seconds')\n",
    "\n",
    "# # path = r''\n",
    "# # booster.save_binary(dmatrix_test_filename)\n",
    "\n",
    "# # save model\n",
    "# bst.save_model(os.path.join(model_folder, 'xgb_70.model'))\n",
    "# # dump model\n",
    "# bst.dump_model(os.path.join(model_folder, 'xgb_70.raw.txt'))\n",
    "\n",
    "# # dump model with feature map\n",
    "# # booster.dump_model('xgb_70.nice.txt', '../data/featmap.txt')\n",
    "# # save dmatrix into binary buffer（数据集保存）\n",
    "# # dtest.save_binary('dtest.buffer')\n",
    "\n",
    "# # Repeat for CPU algorithm\n",
    "# # tmp = time.time()\n",
    "# # param['tree_method'] = 'hist'\n",
    "# # cpu_res = {}\n",
    "# # xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=cpu_res)\n",
    "# # print(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-27T18:46:56.783469Z",
     "start_time": "2019-11-27T18:46:56.489122Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = bst.predict(dtest, ntree_limit=num_round)\n",
    "# conf = confusion_matrix(y_test, y_pred)\n",
    "# score = np.sum(conf.diagonal()) / np.sum(conf)\n",
    "# print(conf, '\\n')\n",
    "# print('fraction:', fraction, 'score:', score, '\\n')\n",
    "# # print(feature_importances(booster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T17:08:33.268827Z",
     "start_time": "2019-11-25T17:08:32.898541Z"
    }
   },
   "outputs": [],
   "source": [
    "# md_pa = os.path.join(model_folder, r'model_no-settings.p')\n",
    "# with gzip.GzipFile(md_pa, 'wb') as file:\n",
    "#     pickle.dump(clf_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2019-11-25T11:36:47.366204Z",
     "start_time": "2019-11-25T11:36:47.319317Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_type = clf.fitted_pipeline_.steps[1]\n",
    "# print(best_type, '\\n')\n",
    "\n",
    "# %time best_type.fit(X_train, y_train)\n",
    "# # y_pred = best_type.predict(X_test)\n",
    "\n",
    "# print(best_type.score(X_test, y_test), '\\n')\n",
    "# # print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(best_type.feature_importances_)\n",
    "\n",
    "# md_pa = os.path.join(model_folder, r'model_clf2.dat')\n",
    "# with open(md_pa, 'wb') as file:\n",
    "#     pickle.dump(best_type, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
