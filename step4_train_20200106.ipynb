{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:26.722688Z",
     "start_time": "2020-01-06T13:37:26.716703Z"
    }
   },
   "outputs": [],
   "source": [
    "log_root = r'D:\\issp_data\\features_total_final_uncompressed'\n",
    "fraction = 1\n",
    "\n",
    "model_folder = r'D:\\issp_data\\model'\n",
    "# test_size = 0.25\n",
    "start_month_train, end_month_train = 4, 5\n",
    "start_month_test, end_month_test = 6, 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.169130Z",
     "start_time": "2020-01-06T13:37:26.726675Z"
    }
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "from typing import Tuple, List\n",
    "\n",
    "import dask.dataframe as dd\n",
    "import gzip\n",
    "import numpy as np\n",
    "import pickle\n",
    "import time\n",
    "\n",
    "from distributed.protocol.serialize import register_generic\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils import resample\n",
    "from tpot import TPOTClassifier\n",
    "register_generic(TPOTClassifier)\n",
    "\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.188014Z",
     "start_time": "2020-01-06T13:37:30.171060Z"
    }
   },
   "outputs": [],
   "source": [
    "shift = 0\n",
    "\n",
    "# max(ts)\n",
    "# min(ts)\n",
    "# diff(ts) = max(ts) - min(ts)\n",
    "# len(ts)\n",
    "# diff(ts) / len(ts) --> density\n",
    "# max(dr)\n",
    "# min(dr)\n",
    "# mean(dr)\n",
    "# median(dr)\n",
    "# var(dr)\n",
    "selected = [r'ts_max', r'ts_min', r'ts_diff', r'ts_len', r'ts_density',\n",
    "            r'dr_max', r'dr_min', r'dr_mean', r'dr_median', r'dr_var']\n",
    "\n",
    "def load_data(st: int, ed: int) -> Tuple['np.array']:\n",
    "    path = os.path.join(log_root, sorted(os.listdir(log_root))[0])\n",
    "#     col_nums = dd.read_csv(path, compression='zip').shape[-1]\n",
    "#     col_nums = dd.read_csv(path).shape[-1] - shift\n",
    "    col_nums = dd.read_csv(path, usecols=selected).shape[-1] - shift\n",
    "    \n",
    "    arr_X, arr_y = np.zeros(col_nums).reshape((-1, col_nums)), np.array([0])\n",
    "    \n",
    "    for fl in os.listdir(log_root)[(st - 1) * 3: ed * 3]:\n",
    "        cata = int(fl[31])\n",
    "        path = os.path.join(log_root, fl)\n",
    "        print(path)\n",
    "#         tmp = dd.read_csv(path, compression='zip')\\\n",
    "#         tmp = dd.read_csv(path)\\\n",
    "        \n",
    "        tmp = dd.read_csv(path, usecols=selected)\\\n",
    "                .compute()\\\n",
    "                .values[:, shift:]\n",
    "        print(tmp.shape)\n",
    "        \n",
    "        arr_X = np.vstack((arr_X, tmp))\n",
    "        arr_y = np.hstack((arr_y, np.array([cata] * tmp.shape[0])))\n",
    "        \n",
    "    return arr_X[1: , :], arr_y[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.206965Z",
     "start_time": "2020-01-06T13:37:30.191006Z"
    }
   },
   "outputs": [],
   "source": [
    "# shift = 2\n",
    "\n",
    "# def load_data(st: int, ed: int) -> Tuple['np.array']:\n",
    "#     path = os.path.join(log_root, sorted(os.listdir(log_root))[0])\n",
    "# #     col_nums = dd.read_csv(path, compression='zip').shape[-1]\n",
    "#     col_nums = dd.read_csv(path).shape[-1] - shift\n",
    "    \n",
    "#     arr_X, arr_y = np.zeros(col_nums).reshape((-1, col_nums)), np.array([0])\n",
    "    \n",
    "#     for fl in os.listdir(log_root)[(st - 1) * 3: ed * 3]:\n",
    "#         cata = int(fl[31])\n",
    "#         path = os.path.join(log_root, fl)\n",
    "#         print(path)\n",
    "# #         tmp = dd.read_csv(path, compression='zip')\\\n",
    "#         tmp = dd.read_csv(path)\\\n",
    "#                 .compute()\\\n",
    "#                 .values[:, shift:]\n",
    "        \n",
    "#         arr_X = np.vstack((arr_X, tmp))\n",
    "#         arr_y = np.hstack((arr_y, np.array([cata] * tmp.shape[0])))\n",
    "        \n",
    "#     return arr_X[1: , :], arr_y[1: ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.222920Z",
     "start_time": "2020-01-06T13:37:30.209955Z"
    }
   },
   "outputs": [],
   "source": [
    "def feature_importances(model_obj) -> List:\n",
    "    path = lambda x: os.path.join(x, os.listdir(x)[0])\n",
    "#     df = dd.read_csv(path(log_root), sep='\\t', compression='zip')\n",
    "    df = dd.read_csv(path(log_root), sep='\\t')\n",
    "#     cols = list(df.compute())[0].split(',')[shift:]\n",
    "    cols = selected\n",
    "\n",
    "    features = model_obj.feature_importances_\\\n",
    "                    .tolist()\n",
    "    result = [(fea, col) for (fea, col) in zip(features, cols)]\n",
    "    return sorted(result, reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.235886Z",
     "start_time": "2020-01-06T13:37:30.226909Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# arr_X, arr_y = load_data(1, 12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:30.246857Z",
     "start_time": "2020-01-06T13:37:30.239875Z"
    }
   },
   "outputs": [],
   "source": [
    "# X, y = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "#                 replace=False, stratify=arr_y, random_state=None)\n",
    "\n",
    "# X_train, X_test, y_train, y_test = train_test_split(\n",
    "#     X, y, test_size=test_size, random_state=None)\n",
    "\n",
    "# print(X_train.shape, y_train.shape)\n",
    "# print(X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:35.294914Z",
     "start_time": "2020-01-06T13:37:30.251843Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201704_104647_0_features.csv\n",
      "(313307, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201704_104647_1_features.csv\n",
      "(185061, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201704_104647_2_features.csv\n",
      "(127174, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201705_104648_0_features.csv\n",
      "(328907, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201705_104648_1_features.csv\n",
      "(190919, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201705_104648_2_features.csv\n",
      "(132772, 10)\n",
      "\n",
      "total:\n",
      " (426, 10) (426,)\n"
     ]
    }
   ],
   "source": [
    "# import train data\n",
    "arr_X, arr_y = load_data(start_month_train, end_month_train)\n",
    "X_train, y_train = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "                            replace=False, stratify=arr_y, random_state=None)\n",
    "\n",
    "print('\\ntotal:\\n', X_train.shape, y_train.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:37.586710Z",
     "start_time": "2020-01-06T13:37:35.297905Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201706_104649_0_features.csv\n",
      "(291474, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201706_104649_1_features.csv\n",
      "(161097, 10)\n",
      "D:\\issp_data\\features_total_final_uncompressed\\s35809_MobileApp_201706_104649_2_features.csv\n",
      "(119131, 10)\n",
      "\n",
      "total:\n",
      " (190, 10) (190,)\n"
     ]
    }
   ],
   "source": [
    "# import test data\n",
    "arr_X, arr_y = load_data(start_month_test, end_month_test)\n",
    "X_test, y_test = resample(arr_X, arr_y, n_samples=arr_X.shape[0]//fraction,\n",
    "                            replace=False, stratify=arr_y, random_state=None)\n",
    "\n",
    "print('\\ntotal:\\n', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:37.594688Z",
     "start_time": "2020-01-06T13:37:37.589700Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# config_dict = {\n",
    "#     'xgboost.XGBClassifier': {\n",
    "#     },\n",
    "#     'sklearn.ensemble.ExtraTreesClassifier': {\n",
    "#     },\n",
    "#     'sklearn.ensemble.GradientBoostingClassifier': {\n",
    "#     }\n",
    "# }\n",
    "\n",
    "# clf = TPOTClassifier(generations=3,\n",
    "#                      population_size=10, \n",
    "#                      n_jobs=-1,\n",
    "#                      verbosity=2,\n",
    "#                      config_dict=config_dict,\n",
    "#                      random_state=None,\n",
    "#                      use_dask=True)\n",
    "\n",
    "# %time clf.fit(X_train, y_train)\n",
    "# print(clf.fitted_pipeline_.steps[1])\n",
    "\n",
    "# print(clf.score(X_test, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:38.105924Z",
     "start_time": "2020-01-06T13:37:37.596682Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=-1)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=-1)]: Done  10 out of  10 | elapsed:    0.0s finished\n",
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "building tree 1 of 10\n",
      "building tree 2 of 10\n",
      "building tree 3 of 10\n",
      "building tree 4 of 10\n",
      "building tree 5 of 10\n",
      "building tree 6 of 10\n",
      "building tree 7 of 10\n",
      "building tree 8 of 10\n",
      "building tree 9 of 10\n",
      "building tree 10 of 10\n",
      "Wall time: 122 ms\n",
      "fraction: 3000\n",
      "0.6842105263157895 \n",
      "\n",
      "[[79 17  1]\n",
      " [10 37  6]\n",
      " [12 14 14]] \n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Parallel(n_jobs=4)]: Using backend ThreadingBackend with 4 concurrent workers.\n",
      "[Parallel(n_jobs=4)]: Done  10 out of  10 | elapsed:    0.0s finished\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.15124166349572132, 'dr_min'),\n",
       " (0.13911552474492936, 'ts_len'),\n",
       " (0.13306980601259982, 'ts_density'),\n",
       " (0.1330435733342815, 'dr_mean'),\n",
       " (0.09332205625897481, 'ts_diff'),\n",
       " (0.09217985895197833, 'dr_max'),\n",
       " (0.08131393968308762, 'dr_var'),\n",
       " (0.07115295678843994, 'ts_min'),\n",
       " (0.06517502923634497, 'ts_max'),\n",
       " (0.04038559149364236, 'dr_median')]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Random forest\n",
    "\n",
    "clf_rf = RandomForestClassifier(verbose=2, n_jobs=-1)\n",
    "%time clf_rf.fit(X_train, y_train)\n",
    "y_pred = clf_rf.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction)\n",
    "print(clf_rf.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "# print(clf_rf.feature_importances_)\n",
    "feature_importances(clf_rf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:38.741715Z",
     "start_time": "2020-01-06T13:37:38.108917Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 261 ms\n",
      "fraction: 3000\n",
      "0.5684210526315789 \n",
      "\n",
      "[[94  3  0]\n",
      " [42  9  2]\n",
      " [30  5  5]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.2030854765041862, 'ts_diff'),\n",
       " (0.15215514555888, 'dr_mean'),\n",
       " (0.138368921783162, 'ts_len'),\n",
       " (0.11872177321777773, 'ts_density'),\n",
       " (0.10700378590321052, 'dr_median'),\n",
       " (0.10100009313311781, 'dr_max'),\n",
       " (0.08432071734681061, 'dr_min'),\n",
       " (0.03978267916961247, 'dr_var'),\n",
       " (0.02891594848976531, 'ts_max'),\n",
       " (0.026645458893477483, 'ts_min')]"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTrees Classifier\n",
    "\n",
    "clf_ext = ExtraTreesClassifier(bootstrap=False, criterion='gini', \n",
    "                               max_features=0.1, min_samples_leaf=3, \n",
    "                               min_samples_split=2, n_estimators=100,\n",
    "                               n_jobs=-1)\n",
    "\n",
    "%time clf_ext.fit(X_train, y_train)\n",
    "y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction)\n",
    "print(clf_ext.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "\n",
    "# print(feature_importances(clf.ext))\n",
    "# print(clf_rf.feature_importances_)\n",
    "feature_importances(clf_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.250262Z",
     "start_time": "2020-01-06T13:37:38.744708Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 120 ms\n",
      "fraction: 3000 score: 0.7 \n",
      "\n",
      "[[84 11  2]\n",
      " [13 34  6]\n",
      " [11 14 15]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.1623521342553966, 'dr_mean'),\n",
       " (0.14013652874408591, 'ts_len'),\n",
       " (0.13015234254085245, 'dr_min'),\n",
       " (0.10255225281182537, 'ts_density'),\n",
       " (0.09739415989118606, 'ts_diff'),\n",
       " (0.09059227814903806, 'dr_max'),\n",
       " (0.07449106539411157, 'ts_max'),\n",
       " (0.07281989409227019, 'dr_var'),\n",
       " (0.0681674253347797, 'ts_min'),\n",
       " (0.061341918786454154, 'dr_median')]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# ExtraTrees Classifier\n",
    "\n",
    "clf_ext = ExtraTreesClassifier(bootstrap=False, class_weight=None, \n",
    "                               criterion='gini', max_depth=None, \n",
    "                               max_features='auto', max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, min_samples_leaf=1, \n",
    "                               min_samples_split=2, \n",
    "                               min_weight_fraction_leaf=0.0, n_estimators=10, \n",
    "#                                n_jobs=None, \n",
    "                               n_jobs=-1, \n",
    "                               oob_score=False, \n",
    "                               random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "%time clf_ext.fit(X_train, y_train)\n",
    "y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction, 'score:', clf_ext.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "feature_importances(clf_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.331048Z",
     "start_time": "2020-01-06T13:37:39.259237Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Wall time: 25.9 ms\n",
      "fraction: 3000 score: 0.6789473684210526 \n",
      "\n",
      "[[83 13  1]\n",
      " [15 30  8]\n",
      " [ 9 15 16]] \n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[(0.15819949547953, 'dr_mean'),\n",
       " (0.13032891710298433, 'dr_min'),\n",
       " (0.12350387437887289, 'ts_len'),\n",
       " (0.12283959005184404, 'ts_density'),\n",
       " (0.10195948647849665, 'dr_max'),\n",
       " (0.09958353620460611, 'ts_diff'),\n",
       " (0.07065322766565044, 'dr_var'),\n",
       " (0.06482618950415252, 'ts_max'),\n",
       " (0.06423852908167482, 'dr_median'),\n",
       " (0.06386715405218825, 'ts_min')]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# # ExtraTrees Classifier\n",
    "\n",
    "clf_ext = ExtraTreesClassifier(bootstrap=False, class_weight=None, \n",
    "                               criterion='gini', max_depth=None, \n",
    "                               max_features='auto', max_leaf_nodes=None,\n",
    "                               min_impurity_decrease=0.0, \n",
    "                               min_impurity_split=None, min_samples_leaf=1, \n",
    "                               min_samples_split=2, \n",
    "                               min_weight_fraction_leaf=0.0, n_estimators=10, \n",
    "                               n_jobs=None, oob_score=False, \n",
    "                               random_state=None, verbose=0, warm_start=False)\n",
    "\n",
    "%time clf_ext.fit(X_train, y_train)\n",
    "y_pred = clf_ext.predict(X_test)\n",
    "\n",
    "print('fraction:', fraction, 'score:', clf_ext.score(X_test, y_test), '\\n')\n",
    "print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "feature_importances(clf_ext)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.338029Z",
     "start_time": "2020-01-06T13:37:39.333042Z"
    }
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "# param = {\n",
    "#     'tree_method': 'gpu_hist', \n",
    "#     'gpu_id': 0\n",
    "# }\n",
    "# clf_xgb = xgb.XGBClassifier(**param)\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# feature_importances(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.348002Z",
     "start_time": "2020-01-06T13:37:39.341021Z"
    }
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "# # param = {\n",
    "# #     'tree_method': 'gpu_hist', \n",
    "# #     'gpu_id': 0\n",
    "# # }\n",
    "# clf_xgb = xgb.XGBClassifier()\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# feature_importances(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.356978Z",
     "start_time": "2020-01-06T13:37:39.352990Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# # XGBClassifier\n",
    "\n",
    "# # clf_xgb = XGBClassifier()\n",
    "# clf_xgb = xgb.XGBClassifier(base_score=0.5, booster='gbtree', \n",
    "#                             colsample_bylevel=1, colsample_bynode=1, \n",
    "#                             colsample_bytree=1, gamma=0, learning_rate=0.1, \n",
    "#                             max_delta_step=0, max_depth=3, min_child_weight=1,\n",
    "#                             missing=None, n_estimators=100, n_jobs=1, \n",
    "# #                             nthread=None, \n",
    "#                             nthread=None, objective='multi:softprob', \n",
    "#                             random_state=0, reg_alpha=0, reg_lambda=1, \n",
    "#                             scale_pos_weight=1, seed=None, silent=None, \n",
    "#                             subsample=1, verbosity=1)\n",
    "\n",
    "# %time clf_xgb.fit(X_train, y_train)\n",
    "# y_pred = clf_xgb.predict(X_test)\n",
    "\n",
    "# print('fraction:', fraction, 'score:', clf_xgb.score(X_test, y_test), '\\n')\n",
    "# print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# feature_importances(clf_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.365955Z",
     "start_time": "2020-01-06T13:37:39.360968Z"
    }
   },
   "outputs": [],
   "source": [
    "# def load_DMatrix(Xt: 'np.array', yt: 'np.array', \n",
    "#                  frac: int) -> Tuple['np.array']:\n",
    "#     step, i = Xt.size // frac, 0\n",
    "    \n",
    "#     while i <= frac:\n",
    "#         st, ed = i * step, (i + 1) * step\n",
    "        \n",
    "# #         yield Xt[st: ed], yt[st: ed]\n",
    "#         yield xgb.DMatrix(Xt[st: ed], label=yt[st: ed])\n",
    "        \n",
    "#         i += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.375928Z",
     "start_time": "2020-01-06T13:37:39.368947Z"
    }
   },
   "outputs": [],
   "source": [
    "# for (x, y) in load_DMatrix(arr_X, arr_y, fraction):\n",
    "#     print(x.size)\n",
    "#     print(y.size)\n",
    "# #     rret\n",
    "# # 0\n",
    "# # 1717435"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.388893Z",
     "start_time": "2020-01-06T13:37:39.380915Z"
    }
   },
   "outputs": [],
   "source": [
    "# # Specify sufficient boosting iterations to reach a minimum\n",
    "# num_round = 3\n",
    "\n",
    "# # Leave most parameters as default\n",
    "# param = {\n",
    "# #     'subsample': 1 / fraction,\n",
    "#     'objective': 'multi:softmax',  # Specify multiclass classification\n",
    "#     'num_class': 3,  # Number of possible output classes\n",
    "#     'tree_method': 'gpu_hist'  # Use GPU accelerated algorithm\n",
    "# }\n",
    "\n",
    "# # Convert input data from numpy to XGBoost format\n",
    "# dtrain = xgb.DMatrix(X_train, label=y_train, nthread=-1)\n",
    "# dtest = xgb.DMatrix(X_test, label=y_test, nthread=-1)\n",
    "# # evallist = [(dtrain, 'train'), (dtest, 'test')]\n",
    "# evallist = [(dtest, 'test')]\n",
    "# gpu_res = {}  # Store accuracy result\n",
    "\n",
    "# # Train model\n",
    "# tmp = time.time()\n",
    "# bst = xgb.train(param, \n",
    "#                 dtrain, \n",
    "# #                 load_DMatrix(arr_X, arr_y, fraction),\n",
    "#                 num_boost_round=num_round, \n",
    "#                 evals=evallist, evals_result=gpu_res)\n",
    "# print(f'GPU Training Time: {time.time() - tmp} seconds')\n",
    "\n",
    "# # path = r''\n",
    "# # booster.save_binary(dmatrix_test_filename)\n",
    "\n",
    "# # save model\n",
    "# bst.save_model(os.path.join(model_folder, 'xgb_70.model'))\n",
    "# # dump model\n",
    "# bst.dump_model(os.path.join(model_folder, 'xgb_70.raw.txt'))\n",
    "\n",
    "# # dump model with feature map\n",
    "# # booster.dump_model('xgb_70.nice.txt', '../data/featmap.txt')\n",
    "# # save dmatrix into binary buffer（数据集保存）\n",
    "# # dtest.save_binary('dtest.buffer')\n",
    "\n",
    "# # Repeat for CPU algorithm\n",
    "# # tmp = time.time()\n",
    "# # param['tree_method'] = 'hist'\n",
    "# # cpu_res = {}\n",
    "# # xgb.train(param, dtrain, num_round, evals=[(dtest, 'test')], evals_result=cpu_res)\n",
    "# # print(\"CPU Training Time: %s seconds\" % (str(time.time() - tmp)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.399865Z",
     "start_time": "2020-01-06T13:37:39.392885Z"
    }
   },
   "outputs": [],
   "source": [
    "# y_pred = bst.predict(dtest, ntree_limit=num_round)\n",
    "# conf = confusion_matrix(y_test, y_pred)\n",
    "# score = np.sum(conf.diagonal()) / np.sum(conf)\n",
    "# print(conf, '\\n')\n",
    "# print('fraction:', fraction, 'score:', score, '\\n')\n",
    "# # print(feature_importances(booster))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.407842Z",
     "start_time": "2020-01-06T13:37:39.402857Z"
    }
   },
   "outputs": [],
   "source": [
    "# md_pa = os.path.join(model_folder, r'model_no-settings.p')\n",
    "# with gzip.GzipFile(md_pa, 'wb') as file:\n",
    "#     pickle.dump(clf_xgb, file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2020-01-06T13:37:39.417815Z",
     "start_time": "2020-01-06T13:37:39.411831Z"
    }
   },
   "outputs": [],
   "source": [
    "# best_type = clf.fitted_pipeline_.steps[1]\n",
    "# print(best_type, '\\n')\n",
    "\n",
    "# %time best_type.fit(X_train, y_train)\n",
    "# # y_pred = best_type.predict(X_test)\n",
    "\n",
    "# print(best_type.score(X_test, y_test), '\\n')\n",
    "# # print(confusion_matrix(y_test, y_pred), '\\n')\n",
    "# print(best_type.feature_importances_)\n",
    "\n",
    "# md_pa = os.path.join(model_folder, r'model_clf2.dat')\n",
    "# with open(md_pa, 'wb') as file:\n",
    "#     pickle.dump(best_type, file)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
